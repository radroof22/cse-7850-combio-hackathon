{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data to `protein_embeddings.parquet`\n",
    "The following cells were used to first preprocess the train.csv file to create the mutated sequences. Then, we run the ESM model to get the embeddings and store these in a parquet file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# get the sequence\n",
    "seq = open('sequence.fasta', 'r').read()\n",
    "seq = seq.split(\"\\n\")[1]\n",
    "\n",
    "# create each mutated sequence using the info\n",
    "sequences = []\n",
    "for i in df['mutant']:\n",
    "    ind = int(i[1:-1])\n",
    "    tmp = seq[:ind] + i[-1] + seq[ind+1:]\n",
    "    sequences.append(tmp)\n",
    "df['Sequence'] = sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import esm\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load pre-trained ESM model and move it to GPU\n",
    "esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()  # Example: ESM-2 model\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "esm_model = esm_model.to(device)\n",
    "esm_model.eval()  # Set to eval mode\n",
    "\n",
    "# Extract ESM embeddings using GPU\n",
    "def extract_esm_embedding(sequence):\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter([(None, sequence)])\n",
    "    batch_tokens = batch_tokens.to(device)  # Move input to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        results = esm_model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "    \n",
    "    token_representations = results[\"representations\"][33]  # Use final layer\n",
    "    sequence_embedding = token_representations.mean(dim=1).squeeze().cpu().numpy()  # Move back to CPU for NumPy\n",
    "    return sequence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply embedding extraction\n",
    "df[\"Embedding\"] = df[\"Sequence\"].apply(lambda seq: extract_esm_embedding(seq))\n",
    "\n",
    "df.to_parquet(\"protein_embeddings.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models\n",
    "We initially train a MLP, LightGBM, and XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('protein_embeddings.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X = np.vstack(df[\"Embedding\"].values)\n",
    "y = df[\"DMS_score\"].values\n",
    "\n",
    "# Convert to PyTorch tensors and move to GPU\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32, device=device).view(-1, 1)  # Reshape for MLP\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/2000, Loss: 0.0412\n",
      "Epoch 200/2000, Loss: 0.0399\n",
      "Epoch 300/2000, Loss: 0.0397\n",
      "Epoch 400/2000, Loss: 0.0397\n",
      "Epoch 500/2000, Loss: 0.0382\n",
      "Epoch 600/2000, Loss: 0.0369\n",
      "Epoch 700/2000, Loss: 0.0365\n",
      "Epoch 800/2000, Loss: 0.0369\n",
      "Epoch 900/2000, Loss: 0.0380\n",
      "Epoch 1000/2000, Loss: 0.0385\n",
      "Epoch 1100/2000, Loss: 0.0359\n",
      "Epoch 1200/2000, Loss: 0.0352\n",
      "Epoch 1300/2000, Loss: 0.0348\n",
      "Epoch 1400/2000, Loss: 0.0398\n",
      "Epoch 1500/2000, Loss: 0.0391\n",
      "Epoch 1600/2000, Loss: 0.0412\n",
      "Epoch 1700/2000, Loss: 0.0412\n",
      "Epoch 1800/2000, Loss: 0.0409\n",
      "Epoch 1900/2000, Loss: 0.0393\n",
      "Epoch 2000/2000, Loss: 0.0381\n",
      "Test MSE: 0.0483\n",
      "MLP Spearman Correlation: 0.3111\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Define a simple MLP regression model using GPU\n",
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLPRegressor, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)  # Single output value\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = MLPRegressor(input_dim=X.shape[1]).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 2000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(X_train)\n",
    "    loss = criterion(predictions, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test)\n",
    "    test_loss = criterion(test_predictions, y_test)\n",
    "print(f\"Test MSE: {test_loss.item():.4f}\")\n",
    "\n",
    "spearman_corr_xgb, _ = spearmanr(y_test.cpu().numpy().flatten(), test_predictions.cpu().numpy().flatten())\n",
    "print(f\"MLP Spearman Correlation: {spearman_corr_xgb:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Spearman Correlation: 0.4481\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Convert to DMatrix (XGBoost's optimized data structure)\n",
    "dtrain = xgb.DMatrix(X_train.cpu().numpy(), label=y_train.cpu().numpy().flatten())\n",
    "dtest = xgb.DMatrix(X_test.cpu().numpy(), label=y_test.cpu().numpy().flatten())\n",
    "\n",
    "# Train XGBoost Model\n",
    "params = {\"objective\": \"reg:squarederror\", \"eval_metric\": \"rmse\"}\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Predict\n",
    "y_pred_xgb = xgb_model.predict(dtest)\n",
    "\n",
    "# Compute Spearman correlation\n",
    "spearman_corr_xgb, _ = spearmanr(y_test.cpu().numpy().flatten(), y_pred_xgb)\n",
    "print(f\"XGBoost Spearman Correlation: {spearman_corr_xgb:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Spearman Correlation: 0.4600\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Train LightGBM Model\n",
    "lgb_train = lgb.Dataset(X_train.cpu().numpy(), label=y_train.cpu().numpy().flatten())\n",
    "\n",
    "params = {\"objective\": \"regression\", \"metric\": \"rmse\"}\n",
    "lgb_model = lgb.train(params, lgb_train, num_boost_round=100)\n",
    "\n",
    "# Predict\n",
    "y_pred_lgb = lgb_model.predict(X_test.cpu().numpy())\n",
    "\n",
    "# Compute Spearman correlation\n",
    "spearman_corr_lgb, _ = spearmanr(y_test.cpu().numpy().flatten(), y_pred_lgb)\n",
    "print(f\"LightGBM Spearman Correlation: {spearman_corr_lgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble of LightGBM & Linear Regression \n",
    "We use linear regression to weigh the different models in the ensemble instead of taking the mean. We use boostrapping to train each model on a different subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each bootstrap training size: 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Bootstrapped LightGBM Models: 100%|██████████| 100/100 [01:20<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped LightGBM Ensemble Spearman Correlation: 0.4947\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Train Ensemble\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Define hyperparameters for LightGBM\n",
    "# lgb_params = {\"objective\": \"regression\", \"metric\": \"rmse\",'learning_rate': 0.04931791757724383, 'num_leaves': 85, 'min_child_samples': 48, 'max_depth': 7, 'subsample': 0.5749253739933733, 'colsample_bytree': 0.8371746709650121,'verbosity':-1}\n",
    "lgb_params = {'learning_rate': 0.07265158061393213, 'num_leaves': 99, 'min_child_samples': 40, 'max_depth': 5, 'subsample': 0.6919800894003186, 'colsample_bytree': 0.5493776294572092}\n",
    "\n",
    "# Number of bootstrapped models\n",
    "num_bootstraps = 100\n",
    "lgb_boot_models = []\n",
    "lgb_predictions = []\n",
    "\n",
    "\n",
    "X_BOOTSTRAP_PROP = 20\n",
    "print(f\"Each bootstrap training size: {len(X_train) // num_bootstraps * X_BOOTSTRAP_PROP}\")\n",
    "\n",
    "progress = tqdm(total=num_bootstraps, desc=\"Training Bootstrapped LightGBM Models\")\n",
    "\n",
    "for i in range(num_bootstraps):\n",
    "    # Bootstrap resampling\n",
    "    X_resampled, y_resampled = resample(X_train.cpu().numpy(), y_train.cpu().numpy().flatten(), replace=True, n_samples=X_train.shape[0], random_state=i)\n",
    "\n",
    "    # Train LightGBM model on resampled data\n",
    "    lgb_train = lgb.Dataset(X_resampled, label=y_resampled)\n",
    "    lgb_model = lgb.train(lgb_params, lgb_train, num_boost_round=100)\n",
    "    \n",
    "    # Store trained model\n",
    "    lgb_boot_models.append(lgb_model)\n",
    "\n",
    "    # Predict on test set\n",
    "    y_pred_lgb = lgb_model.predict(X_test.cpu().numpy())\n",
    "    lgb_predictions.append(y_pred_lgb)\n",
    "\n",
    "    progress.update(1)\n",
    "\n",
    "progress.close()\n",
    "\n",
    "# Average predictions from bootstrapped models\n",
    "y_pred_ensemble = np.mean(np.column_stack(lgb_predictions), axis=1)\n",
    "\n",
    "# Compute Spearman correlation\n",
    "spearman_corr_ensemble, _ = spearmanr(y_test.cpu().numpy().flatten(), y_pred_ensemble)\n",
    "\n",
    "print(f\"Bootstrapped LightGBM Ensemble Spearman Correlation: {spearman_corr_ensemble:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating `X_meta_train`: 100%|██████████| 100/100 [00:00<00:00, 251.56it/s]\n",
      "Predicting for `X_meta_test`: 100%|██████████| 100/100 [00:00<00:00, 561.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(912,) (912,)\n",
      "Meta LightGBM Model Spearman Correlation: 0.9146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Train Meta Predictor\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "progress = tqdm(total=len(lgb_boot_models), desc=\"Generating `X_meta_train`\")\n",
    "X_meta_train = []\n",
    "for m in lgb_boot_models:\n",
    "    X_meta_train.append(m.predict(X_train.cpu().numpy()))\n",
    "    progress.update(1)\n",
    "\n",
    "progress.close()\n",
    "\n",
    "X_meta_train = np.column_stack(X_meta_train)\n",
    "y_meta_train = y_train.cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "# Train a Ridge Regression as the meta-model\n",
    "meta_model = Ridge(alpha=1.0)\n",
    "meta_model.fit(X_meta_train, y_meta_train)\n",
    "\n",
    "## EVAL::\n",
    "# Predict with stacked model\n",
    "progress = tqdm(total=len(lgb_boot_models), desc=\"Predicting for `X_meta_test`\")\n",
    "X_meta_test = []\n",
    "for m in lgb_boot_models:\n",
    "    X_meta_test.append(m.predict(X_test.cpu().numpy()))\n",
    "    progress.update(1)\n",
    "progress.close()\n",
    "X_meta_test = np.column_stack(X_meta_test)\n",
    "y_meta_test = y_train.cpu().numpy().flatten()\n",
    "\n",
    "y_meta_pred = meta_model.predict(X_meta_train)\n",
    "\n",
    "# Compute Spearman correlation\n",
    "print(y_meta_test.shape, y_meta_pred.shape)\n",
    "spearman_corr_stacked, _ = spearmanr(y_meta_test, y_meta_pred)\n",
    "print(f\"Meta LightGBM Model Spearman Correlation: {spearman_corr_stacked:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet('protein_embeddings_test.parquet')\n",
    "X_unlabeled = df_test['Embedding'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlabeled = np.vstack(X_unlabeled)\n",
    "X_unlabeled = torch.tensor(X_unlabeled, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute UCB for LightGBM ensemble\n",
    "# beta = 1.5  # Adjust exploration factor\n",
    "\n",
    "y_pred_all = np.column_stack([model.predict(X_unlabeled.cpu().numpy()) for model in lgb_boot_models])\n",
    "std_pred = np.std(y_pred_all, axis=1)    # Uncertainty (std dev)\n",
    "mean_pred = meta_model.predict(y_pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['E600P', 'A510Y', 'E274I', 'E168V', 'S392Y', 'S517Y', 'E3V',\n",
       "       'D637R', 'A72Y', 'S493Y', 'E398V', 'Q554Y', 'D99L', 'E423I',\n",
       "       'E340R', 'D80R', 'E428K', 'S492Y', 'S439Y', 'E468R', 'D360R',\n",
       "       'E3Y', 'E379Y', 'E15W', 'K355Y', 'D401I', 'D381I', 'N486I', 'D27I',\n",
       "       'E168R', 'N443Y', 'N486W', 'S205Y', 'H353I', 'S271Y', 'N648Y',\n",
       "       'N486L', 'E299I', 'E3R', 'Q146Y', 'E600R', 'E359I', 'E340V',\n",
       "       'D37I', 'D637F', 'S263Y', 'K26F', 'E278V', 'N648I', 'E600I',\n",
       "       'Q476Y', 'D37R', 'E3W', 'C129Y', 'E640V', 'D187I', 'W420P',\n",
       "       'N643Y', 'Q526Y', 'E415V', 'E15Y', 'E600Y', 'E135R', 'S9Y',\n",
       "       'N488M', 'E274R', 'E600V', 'S483Y', 'Q570Y', 'D190I', 'S351Y',\n",
       "       'P257I', 'Q163Y', 'S20Y', 'E640W', 'S411Y', 'Q484Y', 'E168I',\n",
       "       'Q508Y', 'N546W', 'Q132Y', 'P342I', 'S409Y', 'W560I', 'E428R',\n",
       "       'Q277Y', 'S113Y', 'N74Y', 'S429Y', 'S54Y', 'Q378Y', 'S183Y',\n",
       "       'N614Y', 'E165V', 'D103I', 'N546Y', 'N486M', 'N546M', 'E358V',\n",
       "       'N488Y'], dtype=object)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rohan's Version\n",
    "ucb_scores = mean_pred + 4.6399 * std_pred\n",
    "top_mutations = np.argsort(ucb_scores)[-100:]\n",
    "df_test.iloc[top_mutations]['mutant'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mutant</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>ucb_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1D</td>\n",
       "      <td>MDNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>[0.1987293, 0.17874913, 0.011203687, 0.3522696...</td>\n",
       "      <td>0.715398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V1Y</td>\n",
       "      <td>MYNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>[0.20150843, 0.16766307, 0.010554179, 0.351026...</td>\n",
       "      <td>0.747625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V1C</td>\n",
       "      <td>MCNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>[0.19926624, 0.17924884, 0.0091279205, 0.35230...</td>\n",
       "      <td>0.720665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V1A</td>\n",
       "      <td>MANEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>[0.19462435, 0.18044756, 0.006854555, 0.353092...</td>\n",
       "      <td>0.727539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V1E</td>\n",
       "      <td>MENEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>[0.19793293, 0.18368268, 0.0076862425, 0.35060...</td>\n",
       "      <td>0.714736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11319</th>\n",
       "      <td>P655S</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>[0.19556434, 0.1741927, 0.015259004, 0.3553321...</td>\n",
       "      <td>0.719264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11320</th>\n",
       "      <td>P655T</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>[0.18834189, 0.17466125, 0.0054028304, 0.35398...</td>\n",
       "      <td>0.751059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11321</th>\n",
       "      <td>P655V</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>[0.18966806, 0.18034382, -0.005223298, 0.35101...</td>\n",
       "      <td>0.751438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11322</th>\n",
       "      <td>P655A</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>[0.18700847, 0.18019429, -0.0006385201, 0.3556...</td>\n",
       "      <td>0.747327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11323</th>\n",
       "      <td>P655W</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>[0.18885885, 0.17823942, -0.0035740493, 0.3552...</td>\n",
       "      <td>0.744028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11324 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mutant                                           Sequence  \\\n",
       "0        V1D  MDNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "1        V1Y  MYNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "2        V1C  MCNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "3        V1A  MANEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "4        V1E  MENEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "...      ...                                                ...   \n",
       "11319  P655S  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "11320  P655T  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "11321  P655V  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "11322  P655A  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "11323  P655W  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "\n",
       "                                               Embedding  ucb_scores  \n",
       "0      [0.1987293, 0.17874913, 0.011203687, 0.3522696...    0.715398  \n",
       "1      [0.20150843, 0.16766307, 0.010554179, 0.351026...    0.747625  \n",
       "2      [0.19926624, 0.17924884, 0.0091279205, 0.35230...    0.720665  \n",
       "3      [0.19462435, 0.18044756, 0.006854555, 0.353092...    0.727539  \n",
       "4      [0.19793293, 0.18368268, 0.0076862425, 0.35060...    0.714736  \n",
       "...                                                  ...         ...  \n",
       "11319  [0.19556434, 0.1741927, 0.015259004, 0.3553321...    0.719264  \n",
       "11320  [0.18834189, 0.17466125, 0.0054028304, 0.35398...    0.751059  \n",
       "11321  [0.18966806, 0.18034382, -0.005223298, 0.35101...    0.751438  \n",
       "11322  [0.18700847, 0.18019429, -0.0006385201, 0.3556...    0.747327  \n",
       "11323  [0.18885885, 0.17823942, -0.0035740493, 0.3552...    0.744028  \n",
       "\n",
       "[11324 rows x 4 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"ucb_scores\"] = ucb_scores\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['L589G', 'E231N', 'E468G', 'W499N', 'L631P', 'L155N', 'F579T',\n",
       "       'L125G', 'L75T', 'L642G', 'A510G', 'F59G', 'A395G', 'I478G',\n",
       "       'F514G', 'L639P', 'D624Y', 'E184N', 'A301G', 'A310G', 'L525T',\n",
       "       'F64G', 'F206G', 'R265P', 'A83G', 'L471T', 'L404P', 'V282G',\n",
       "       'L466A', 'L627T', 'R265N', 'L273N', 'I487G', 'E427N', 'L627G',\n",
       "       'E274N', 'F230G', 'R387G', 'L155T', 'L10G', 'A327G', 'I364G',\n",
       "       'D613N', 'D494N', 'L213N', 'F365G', 'E278G', 'L317M', 'I547G',\n",
       "       'L407G', 'L125T', 'D288N', 'E414N', 'D244N', 'F563G', 'P626G',\n",
       "       'L452G', 'L14G', 'L631T', 'F63C', 'I607G', 'L459P', 'L539P',\n",
       "       'E640N', 'W560T', 'L525P', 'W348P', 'L75P', 'W454N', 'L147G',\n",
       "       'L466T', 'E166N', 'D37Q', 'F431G', 'E46N', 'A349G', 'F256G',\n",
       "       'I481G', 'A367G', 'V634G', 'L641G', 'L346T', 'M580G', 'I496G',\n",
       "       'L300M', 'L155G', 'I181G', 'F405G', 'F238G', 'F434G', 'L620M',\n",
       "       'D187G', 'I374G', 'L121G', 'L267G', 'W94P', 'F171G', 'L346M',\n",
       "       'D91G', 'L639G'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sai's Version\n",
    "ucb_scores = std_pred\n",
    "top_mutations = np.argsort(ucb_scores)[-100:]\n",
    "df_test.iloc[top_mutations]['mutant'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = list(df_test.iloc[top_mutations]['mutant'].values)\n",
    "f = open('query.txt','w')\n",
    "for i in arr:\n",
    "    f.write(i+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# TODO: Delete me\n",
    "# test\n",
    "sai_test = []\n",
    "with open(\"query_backup.txt\", \"r\") as f:\n",
    "    data = f.read()\n",
    "    sai_test = data.splitlines()\n",
    "rohan_test = []\n",
    "with open(\"query.txt\", \"r\") as f:\n",
    "    data = f.read()\n",
    "    rohan_test = data.splitlines()\n",
    "\n",
    "val = len(set(rohan_test) & set(sai_test))\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating protein_embeddings_test.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import esm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load pre-trained ESM model and move it to GPU\n",
    "esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()  # Example: ESM-2 model\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "esm_model = esm_model.to(device)\n",
    "esm_model.eval()  # Set to eval mode\n",
    "\n",
    "# Extract ESM embeddings using GPU\n",
    "def extract_esm_embedding(sequence):\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter([(None, sequence)])\n",
    "    batch_tokens = batch_tokens.to(device)  # Move input to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        results = esm_model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "    \n",
    "    token_representations = results[\"representations\"][33]  # Use final layer\n",
    "    sequence_embedding = token_representations.mean(dim=1).squeeze().cpu().numpy()  # Move back to CPU for NumPy\n",
    "    return sequence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m df_test = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mtest.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m df_test[\u001b[33m'\u001b[39m\u001b[33mSequence\u001b[39m\u001b[33m'\u001b[39m] = df_test[\u001b[33m'\u001b[39m\u001b[33mmutant\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: seq[:\u001b[38;5;28mint\u001b[39m(x[\u001b[32m1\u001b[39m:-\u001b[32m1\u001b[39m])] + x[-\u001b[32m1\u001b[39m] + seq[\u001b[38;5;28mint\u001b[39m(x[\u001b[32m1\u001b[39m:-\u001b[32m1\u001b[39m])+\u001b[32m1\u001b[39m:])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df_test[\u001b[33m'\u001b[39m\u001b[33mEmbedding\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSequence\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_esm_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m df_test.to_parquet(\u001b[33m\"\u001b[39m\u001b[33mprotein_embeddings_test.parquet\u001b[39m\u001b[33m\"\u001b[39m, engine=\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage/ice1/2/4/rmehta98/compbio_env/lib/python3.13/site-packages/pandas/core/series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage/ice1/2/4/rmehta98/compbio_env/lib/python3.13/site-packages/pandas/core/apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage/ice1/2/4/rmehta98/compbio_env/lib/python3.13/site-packages/pandas/core/apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage/ice1/2/4/rmehta98/compbio_env/lib/python3.13/site-packages/pandas/core/base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/storage/ice1/2/4/rmehta98/compbio_env/lib/python3.13/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(seq)\u001b[39m\n\u001b[32m      1\u001b[39m df_test = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mtest.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m df_test[\u001b[33m'\u001b[39m\u001b[33mSequence\u001b[39m\u001b[33m'\u001b[39m] = df_test[\u001b[33m'\u001b[39m\u001b[33mmutant\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: seq[:\u001b[38;5;28mint\u001b[39m(x[\u001b[32m1\u001b[39m:-\u001b[32m1\u001b[39m])] + x[-\u001b[32m1\u001b[39m] + seq[\u001b[38;5;28mint\u001b[39m(x[\u001b[32m1\u001b[39m:-\u001b[32m1\u001b[39m])+\u001b[32m1\u001b[39m:])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df_test[\u001b[33m'\u001b[39m\u001b[33mEmbedding\u001b[39m\u001b[33m'\u001b[39m] = df_test[\u001b[33m'\u001b[39m\u001b[33mSequence\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m seq: \u001b[43mextract_esm_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      4\u001b[39m df_test.to_parquet(\u001b[33m\"\u001b[39m\u001b[33mprotein_embeddings_test.parquet\u001b[39m\u001b[33m\"\u001b[39m, engine=\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mextract_esm_embedding\u001b[39m\u001b[34m(sequence)\u001b[39m\n\u001b[32m     25\u001b[39m     results = esm_model(batch_tokens, repr_layers=[\u001b[32m33\u001b[39m], return_contacts=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     27\u001b[39m token_representations = results[\u001b[33m\"\u001b[39m\u001b[33mrepresentations\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m33\u001b[39m]  \u001b[38;5;66;03m# Use final layer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m sequence_embedding = \u001b[43mtoken_representations\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.numpy()  \u001b[38;5;66;03m# Move back to CPU for NumPy\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sequence_embedding\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test['Sequence'] = df_test['mutant'].apply(lambda x: seq[:int(x[1:-1])] + x[-1] + seq[int(x[1:-1])+1:])\n",
    "df_test['Embedding'] = df_test['Sequence'].apply(lambda seq: extract_esm_embedding(seq))\n",
    "df_test.to_parquet(\"protein_embeddings_test.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Optimal Hyperparams for LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 16:54:57,473] A new study created in memory with name: no-name-1438afd7-4cab-4c82-ba6d-03feabcc94d8\n",
      "/tmp/ipykernel_1554313/1352214443.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n",
      "/tmp/ipykernel_1554313/1352214443.py:12: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
      "/tmp/ipykernel_1554313/1352214443.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
      "[I 2025-03-26 16:55:00,443] Trial 0 finished with value: 0.5072833872861628 and parameters: {'learning_rate': 0.0375190915808658, 'num_leaves': 48, 'min_child_samples': 35, 'max_depth': 8, 'subsample': 0.7996854177443944, 'colsample_bytree': 0.9990164114775317}. Best is trial 0 with value: 0.5072833872861628.\n",
      "[I 2025-03-26 16:55:01,680] Trial 1 finished with value: 0.4813973614320093 and parameters: {'learning_rate': 0.12059683501752148, 'num_leaves': 32, 'min_child_samples': 44, 'max_depth': 7, 'subsample': 0.6157079979887132, 'colsample_bytree': 0.776285675273871}. Best is trial 0 with value: 0.5072833872861628.\n",
      "[I 2025-03-26 16:55:03,038] Trial 2 finished with value: 0.4643573561468603 and parameters: {'learning_rate': 0.05311805486859418, 'num_leaves': 65, 'min_child_samples': 10, 'max_depth': 4, 'subsample': 0.9192669582983908, 'colsample_bytree': 0.9648149892525071}. Best is trial 0 with value: 0.5072833872861628.\n",
      "[I 2025-03-26 16:55:05,592] Trial 3 finished with value: 0.45932483408685837 and parameters: {'learning_rate': 0.013838190943949514, 'num_leaves': 34, 'min_child_samples': 14, 'max_depth': 6, 'subsample': 0.7243000130585396, 'colsample_bytree': 0.8973730747448987}. Best is trial 0 with value: 0.5072833872861628.\n",
      "[I 2025-03-26 16:55:07,102] Trial 4 finished with value: 0.47117487697796856 and parameters: {'learning_rate': 0.05402331322851582, 'num_leaves': 92, 'min_child_samples': 26, 'max_depth': 8, 'subsample': 0.8837662270763451, 'colsample_bytree': 0.5022723338802151}. Best is trial 0 with value: 0.5072833872861628.\n",
      "[I 2025-03-26 16:55:08,068] Trial 5 finished with value: 0.43170291464616956 and parameters: {'learning_rate': 0.031485783791063024, 'num_leaves': 41, 'min_child_samples': 12, 'max_depth': 3, 'subsample': 0.9799191273683183, 'colsample_bytree': 0.9217256086414753}. Best is trial 0 with value: 0.5072833872861628.\n",
      "[I 2025-03-26 16:55:08,658] Trial 6 finished with value: 0.4747094377890472 and parameters: {'learning_rate': 0.08715906766368747, 'num_leaves': 22, 'min_child_samples': 9, 'max_depth': 3, 'subsample': 0.5054800860077884, 'colsample_bytree': 0.7364459627689681}. Best is trial 0 with value: 0.5072833872861628.\n",
      "[I 2025-03-26 16:55:09,489] Trial 7 finished with value: 0.47961135018287065 and parameters: {'learning_rate': 0.1969850100929892, 'num_leaves': 35, 'min_child_samples': 31, 'max_depth': 5, 'subsample': 0.593189171659335, 'colsample_bytree': 0.62507746823604}. Best is trial 0 with value: 0.5072833872861628.\n",
      "[I 2025-03-26 16:55:10,651] Trial 8 finished with value: 0.4923381990500319 and parameters: {'learning_rate': 0.04182549810394624, 'num_leaves': 78, 'min_child_samples': 43, 'max_depth': 6, 'subsample': 0.7634370941631929, 'colsample_bytree': 0.6356483595176352}. Best is trial 0 with value: 0.5072833872861628.\n",
      "[I 2025-03-26 16:55:13,079] Trial 9 finished with value: 0.4875603152151764 and parameters: {'learning_rate': 0.024019990954860636, 'num_leaves': 68, 'min_child_samples': 21, 'max_depth': 9, 'subsample': 0.766789390170864, 'colsample_bytree': 0.6270075674971165}. Best is trial 0 with value: 0.5072833872861628.\n",
      "[I 2025-03-26 16:55:14,914] Trial 10 finished with value: 0.4757730459620745 and parameters: {'learning_rate': 0.010884190734798403, 'num_leaves': 49, 'min_child_samples': 34, 'max_depth': 10, 'subsample': 0.8441488508805863, 'colsample_bytree': 0.8264196017127622}. Best is trial 0 with value: 0.5072833872861628.\n",
      "[I 2025-03-26 16:55:16,158] Trial 11 finished with value: 0.4814743097624711 and parameters: {'learning_rate': 0.026778282283227553, 'num_leaves': 87, 'min_child_samples': 48, 'max_depth': 7, 'subsample': 0.7595745031683645, 'colsample_bytree': 0.6677078371194073}. Best is trial 0 with value: 0.5072833872861628.\n",
      "[I 2025-03-26 16:55:17,392] Trial 12 finished with value: 0.5074813267414953 and parameters: {'learning_rate': 0.04429340117741879, 'num_leaves': 75, 'min_child_samples': 39, 'max_depth': 6, 'subsample': 0.7026943741098235, 'colsample_bytree': 0.5143125650529156}. Best is trial 12 with value: 0.5074813267414953.\n",
      "[I 2025-03-26 16:55:18,137] Trial 13 finished with value: 0.4618190737196548 and parameters: {'learning_rate': 0.01752339992136615, 'num_leaves': 10, 'min_child_samples': 37, 'max_depth': 8, 'subsample': 0.6788309737382492, 'colsample_bytree': 0.5073912939283418}. Best is trial 12 with value: 0.5074813267414953.\n",
      "[I 2025-03-26 16:55:19,219] Trial 14 finished with value: 0.4846352661795973 and parameters: {'learning_rate': 0.07642762940780048, 'num_leaves': 60, 'min_child_samples': 38, 'max_depth': 5, 'subsample': 0.8193385508354231, 'colsample_bytree': 0.8491170755192998}. Best is trial 12 with value: 0.5074813267414953.\n",
      "[I 2025-03-26 16:55:21,162] Trial 15 finished with value: 0.48359190756721787 and parameters: {'learning_rate': 0.037397209258922426, 'num_leaves': 79, 'min_child_samples': 25, 'max_depth': 8, 'subsample': 0.6609621432184194, 'colsample_bytree': 0.7251890439409863}. Best is trial 12 with value: 0.5074813267414953.\n",
      "[I 2025-03-26 16:55:22,896] Trial 16 finished with value: 0.4848580113467235 and parameters: {'learning_rate': 0.021710226865690234, 'num_leaves': 51, 'min_child_samples': 50, 'max_depth': 10, 'subsample': 0.5417487547456579, 'colsample_bytree': 0.9940162835825798}. Best is trial 12 with value: 0.5074813267414953.\n",
      "[I 2025-03-26 16:55:23,796] Trial 17 finished with value: 0.5136751611046504 and parameters: {'learning_rate': 0.07265158061393213, 'num_leaves': 99, 'min_child_samples': 40, 'max_depth': 5, 'subsample': 0.6919800894003186, 'colsample_bytree': 0.5493776294572092}. Best is trial 17 with value: 0.5136751611046504.\n",
      "[I 2025-03-26 16:55:24,592] Trial 18 finished with value: 0.4774542657348606 and parameters: {'learning_rate': 0.07540249100693887, 'num_leaves': 95, 'min_child_samples': 42, 'max_depth': 5, 'subsample': 0.6896405462111257, 'colsample_bytree': 0.5570128561335526}. Best is trial 17 with value: 0.5136751611046504.\n",
      "[I 2025-03-26 16:55:25,338] Trial 19 finished with value: 0.4963815300723873 and parameters: {'learning_rate': 0.13796215694956426, 'num_leaves': 99, 'min_child_samples': 19, 'max_depth': 4, 'subsample': 0.6285662229792027, 'colsample_bytree': 0.5613887526719894}. Best is trial 17 with value: 0.5136751611046504.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LightGBM Parameters: {'learning_rate': 0.07265158061393213, 'num_leaves': 99, 'min_child_samples': 40, 'max_depth': 5, 'subsample': 0.6919800894003186, 'colsample_bytree': 0.5493776294572092}\n"
     ]
    }
   ],
   "source": [
    "#Best LightGBM Parameters: {'learning_rate': 0.04931791757724383, 'num_leaves': 85, 'min_child_samples': 48, 'max_depth': 7, 'subsample': 0.5749253739933733, 'colsample_bytree': 0.8371746709650121}\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 10, 100),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 50),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
    "    }\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train.cpu().numpy(), label=y_train.cpu().numpy().flatten())\n",
    "    lgb_model = lgb.train(params, lgb_train, num_boost_round=100)\n",
    "    \n",
    "    y_pred = lgb_model.predict(X_test.cpu().numpy())\n",
    "    spearman_corr, _ = spearmanr(y_test.cpu().numpy().flatten(), y_pred)\n",
    "    \n",
    "    return spearman_corr\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best LightGBM Parameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Beta\n",
    "There is not much difference amongst the top options, so we just use 1.5 for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 17:17:37,534] A new study created in memory with name: no-name-fb68060a-1bed-4d41-a5ee-4e270b054f99\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:37,679] Trial 0 finished with value: 0.5060436079354995 and parameters: {'beta': 2.436792726322021}. Best is trial 0 with value: 0.5060436079354995.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:37,786] Trial 1 finished with value: 0.5058811052113006 and parameters: {'beta': 2.9506393718441983}. Best is trial 0 with value: 0.5060436079354995.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:37,891] Trial 2 finished with value: 0.5041836857899963 and parameters: {'beta': 0.8021897165015934}. Best is trial 0 with value: 0.5060436079354995.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:38,138] Trial 3 finished with value: 0.505564199587162 and parameters: {'beta': 1.8817406505164143}. Best is trial 0 with value: 0.5060436079354995.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:38,326] Trial 4 finished with value: 0.5061205562659612 and parameters: {'beta': 3.0511822411312}. Best is trial 4 with value: 0.5061205562659612.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:38,433] Trial 5 finished with value: 0.5054103029262387 and parameters: {'beta': 1.5758020050646544}. Best is trial 4 with value: 0.5061205562659612.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:38,540] Trial 6 finished with value: 0.5074271591667624 and parameters: {'beta': 3.81426957545498}. Best is trial 6 with value: 0.5074271591667624.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:38,646] Trial 7 finished with value: 0.5054386523111455 and parameters: {'beta': 1.37671653581374}. Best is trial 6 with value: 0.5074271591667624.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:38,753] Trial 8 finished with value: 0.5061737113626618 and parameters: {'beta': 2.298074023259662}. Best is trial 6 with value: 0.5074271591667624.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:38,862] Trial 9 finished with value: 0.5066455261257562 and parameters: {'beta': 3.3061738659326387}. Best is trial 6 with value: 0.5074271591667624.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:38,971] Trial 10 finished with value: 0.5077126779718968 and parameters: {'beta': 4.792969963243967}. Best is trial 10 with value: 0.5077126779718968.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:39,080] Trial 11 finished with value: 0.5076438294656942 and parameters: {'beta': 4.836823965349862}. Best is trial 10 with value: 0.5077126779718968.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:39,189] Trial 12 finished with value: 0.5075537189208112 and parameters: {'beta': 4.807825153882159}. Best is trial 10 with value: 0.5077126779718968.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:39,299] Trial 13 finished with value: 0.507733940010577 and parameters: {'beta': 4.967901327331511}. Best is trial 13 with value: 0.507733940010577.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:39,408] Trial 14 finished with value: 0.5079161860564075 and parameters: {'beta': 4.1136033563416685}. Best is trial 14 with value: 0.5079161860564075.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:39,534] Trial 15 finished with value: 0.5080478082006183 and parameters: {'beta': 4.011824398473935}. Best is trial 15 with value: 0.5080478082006183.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:39,645] Trial 16 finished with value: 0.5072783248960009 and parameters: {'beta': 3.932465139095845}. Best is trial 15 with value: 0.5080478082006183.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:39,757] Trial 17 finished with value: 0.5081151379897724 and parameters: {'beta': 4.0726331401359}. Best is trial 17 with value: 0.5081151379897724.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:39,868] Trial 18 finished with value: 0.5077860826292452 and parameters: {'beta': 4.178362688010405}. Best is trial 17 with value: 0.5081151379897724.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:39,978] Trial 19 finished with value: 0.5071553088150653 and parameters: {'beta': 3.517134281515273}. Best is trial 17 with value: 0.5081151379897724.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:40,087] Trial 20 finished with value: 0.5070778542455874 and parameters: {'beta': 4.233804341260102}. Best is trial 17 with value: 0.5081151379897724.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:40,203] Trial 21 finished with value: 0.5072160574970088 and parameters: {'beta': 4.388084138003088}. Best is trial 17 with value: 0.5081151379897724.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:40,314] Trial 22 finished with value: 0.5067958791135663 and parameters: {'beta': 3.685021280180282}. Best is trial 17 with value: 0.5081151379897724.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:40,427] Trial 23 finished with value: 0.5059413476542279 and parameters: {'beta': 3.0095205446697273}. Best is trial 17 with value: 0.5081151379897724.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:40,539] Trial 24 finished with value: 0.5072808560910819 and parameters: {'beta': 4.393138949622721}. Best is trial 17 with value: 0.5081151379897724.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:40,700] Trial 25 finished with value: 0.5067325992365419 and parameters: {'beta': 3.3010711782971405}. Best is trial 17 with value: 0.5081151379897724.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:40,930] Trial 26 finished with value: 0.5030507228717501 and parameters: {'beta': 0.11300704403004991}. Best is trial 17 with value: 0.5081151379897724.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:41,038] Trial 27 finished with value: 0.5079556726996708 and parameters: {'beta': 4.096773293963684}. Best is trial 17 with value: 0.5081151379897724.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:41,148] Trial 28 finished with value: 0.5079232734026342 and parameters: {'beta': 4.548111506353317}. Best is trial 17 with value: 0.5081151379897724.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:41,262] Trial 29 finished with value: 0.5067194370221207 and parameters: {'beta': 3.572138406798182}. Best is trial 17 with value: 0.5081151379897724.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:41,371] Trial 30 finished with value: 0.5060805633836818 and parameters: {'beta': 2.4704857214816958}. Best is trial 17 with value: 0.5081151379897724.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:41,480] Trial 31 finished with value: 0.5078058259508769 and parameters: {'beta': 4.484622402273845}. Best is trial 17 with value: 0.5081151379897724.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:41,591] Trial 32 finished with value: 0.5076306672512731 and parameters: {'beta': 3.9786703254500635}. Best is trial 17 with value: 0.5081151379897724.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:41,701] Trial 33 finished with value: 0.508173355476635 and parameters: {'beta': 4.639879880987214}. Best is trial 33 with value: 0.508173355476635.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:41,810] Trial 34 finished with value: 0.5076048490614471 and parameters: {'beta': 3.3892775520896334}. Best is trial 33 with value: 0.508173355476635.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:41,923] Trial 35 finished with value: 0.5049233009926584 and parameters: {'beta': 2.828003191142267}. Best is trial 33 with value: 0.508173355476635.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:42,032] Trial 36 finished with value: 0.5081551308720519 and parameters: {'beta': 4.596706500765905}. Best is trial 33 with value: 0.508173355476635.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:42,142] Trial 37 finished with value: 0.5076853410650222 and parameters: {'beta': 4.5709319079916435}. Best is trial 33 with value: 0.508173355476635.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:42,251] Trial 38 finished with value: 0.5073998222598878 and parameters: {'beta': 3.8179875117558075}. Best is trial 33 with value: 0.508173355476635.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:42,361] Trial 39 finished with value: 0.505794032100515 and parameters: {'beta': 2.0099541834459345}. Best is trial 33 with value: 0.508173355476635.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:42,470] Trial 40 finished with value: 0.5054148590773843 and parameters: {'beta': 2.6965959179222843}. Best is trial 33 with value: 0.508173355476635.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:42,579] Trial 41 finished with value: 0.5071811270048913 and parameters: {'beta': 4.2236380660931125}. Best is trial 33 with value: 0.508173355476635.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:42,689] Trial 42 finished with value: 0.5080933697120761 and parameters: {'beta': 4.654825861673589}. Best is trial 33 with value: 0.508173355476635.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:42,799] Trial 43 finished with value: 0.5081561433500843 and parameters: {'beta': 4.649847902235143}. Best is trial 33 with value: 0.508173355476635.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:42,909] Trial 44 finished with value: 0.5077977261266177 and parameters: {'beta': 4.997517154595944}. Best is trial 33 with value: 0.508173355476635.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:43,028] Trial 45 finished with value: 0.5080933697120761 and parameters: {'beta': 4.653653809821194}. Best is trial 33 with value: 0.508173355476635.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:43,138] Trial 46 finished with value: 0.5074231092546329 and parameters: {'beta': 4.742622511431888}. Best is trial 33 with value: 0.508173355476635.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:43,249] Trial 47 finished with value: 0.5073127491491022 and parameters: {'beta': 4.370098943935733}. Best is trial 33 with value: 0.508173355476635.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:43,454] Trial 48 finished with value: 0.507907073754116 and parameters: {'beta': 4.978950547486898}. Best is trial 33 with value: 0.508173355476635.\n",
      "/tmp/ipykernel_1554313/1317211863.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
      "[I 2025-03-26 17:17:43,579] Trial 49 finished with value: 0.5080002217330961 and parameters: {'beta': 4.69073740102609}. Best is trial 33 with value: 0.508173355476635.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Beta: 4.6399\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Function to optimize beta\n",
    "def optimize_beta(trial):\n",
    "    beta = trial.suggest_uniform(\"beta\", 0.1, 5.0)  # Search range\n",
    "    \n",
    "    ensemble_pred = np.column_stack([model.predict(X_test.cpu().numpy()) for model in lgb_boot_models])\n",
    "    std_pred = np.std(ensemble_pred, axis=1)    # Uncertainty (std dev)\n",
    "    mean_pred = meta_model.predict(ensemble_pred)\n",
    "\n",
    "    ucb_scores = mean_pred + beta * std_pred\n",
    "\n",
    "\n",
    "    # Compute Spearman correlation on these selected samples\n",
    "    spearman_corr, _ = spearmanr(y_test.cpu().numpy().flatten(), ucb_scores)\n",
    "\n",
    "    return spearman_corr\n",
    "\n",
    "# Run optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(optimize_beta, n_trials=50)\n",
    "\n",
    "# Get best beta value\n",
    "best_beta = study.best_params[\"beta\"]\n",
    "print(f\"Optimized Beta: {best_beta:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_stacked.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain with Updated Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compbiohack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
